# capstone_project

Raw Data Collection & Preprocessing

ADNI Data Adapter (concise_auto_swiss.py): Raw inputs from ADNI do not have brain masks. For training purposes, a data adapter was built specifically for ADNI data that automatically generates brain masks by Swiss Skull Stripper, a 3D Slicer extension that implements automatic skull stripping. This adapter also converts raw MRI images as well as new-generated masks into npy files to reduce I/O time in later phases. All npy files are automatically categorized based on their contents (image or mask). This adapter has to execute in the 3D Slicer Python interpreter. 

Oxford Data Adapter (Oxford_data_adapter.py): Raw inputs from Oxford do contain brain masks. Therefore, the data adapter for Oxford data simply converts images and masks into npy files and puts them into different categories just as the last two tasks of the f data adapter. This adapter has to execute in the 3D Slicer Python interpreter.

Preprocessor (train_test_maker.py/reduced_train_test_maker.py): The preprocessor takes outputs of data adapters and then converts them into slices. For visualization and normalization purposes, all slices are stored in jpg files since values in pixels are guaranteed to be in [0, 255]. A output coordinator is also built-in to put slices into different categories (testing image/mask & training image/mask). Specifically,  to improve overall efficiency, the “reduced” version of the preprocessor removes slices without any brain part for training data.

Model Building & Prediction:

Data Configurator (data_configurator.py): The data configurator takes outputs of previous phases and concatenates slices into different npy files accordingly for the learning algorithm.

Training & Prediction (unet.py): This is where our learning algorithm allocates. Currently, our learning algorithm was adapted from an open source code but was significantly refactored to make more sense. Basically, this code takes in intermediate files prepared by the data configurator and does training under our customized settings. The best model is also stored for later uses. Outputs of the prediction phase (masks) are converted into jpg files and also categorized for the post-processing phase. 
Post-processing:

Accuracy Computer (compute_accuracy.py): After the prediction phase finishes, the average accuracy of the prediction will be computed. 

Output Visualizer (postprocess.py): Since currently we have not figured out a good way to statistically evaluate our pipeline, we simply visualize the outputs in the post-processing phase. In detail, each mask is combined with the corresponding image and the resultant combinations are stacked into a 3D image file (tiff). This process is applied on both masks generated in the prediction phase as well as these considered as ground truth labels. Testing accuracy is also stored in the file name of each combination that contains the mask generated by the prediction phase. 

Other Helpers

Execution Coordinator (test_unet.py): Since our pipeline is highly modularized, an execution coordinator was also built to enable codes in the model building phase, the prediction phase and the post-processing phase to execute in sequence without any corruption.

Data Eraser (clear_all.py): Two data erasers were also made to automatically erase all outdated files, especially all intermediate files, at the beginning of the execution of our pipeline.
